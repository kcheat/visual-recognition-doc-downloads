{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classifications"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, we will be creating a custom model using IBM Watson Natural Language Understanding (NLU) Classifications feature using the Python SDK for IBM cloud. If you need to install the Python SDK, please visit [https://github.com/watson-developer-cloud/python-sdk](https://github.com/watson-developer-cloud/python-sdk). \n",
    "\n",
    "We will go through the following functionalities:\n",
    "- [How to Create Training Data](#How-to-Create-Training-Data)\n",
    "   - [Create a JSON File from Data](#2.-Create-JSON-file-from-Data)\n",
    "   - [Convert Data from NLC to NLU Format](#Convert-Data-from-NLC-to-NLU-Format-(Optional-to-Run))\n",
    "   - [Fetch Data From NLC](#Fetch-Data-From-NLC-(Optional-to-Run))\n",
    "- [How to Train a NLU Classifications Model](#3.-How-to-Train-a-NLU-Classifications-Model)\n",
    "- [How to Get Status of a NLU Classifications Model](#4.-How-to-Get-Status-of-a-NLU-Classifications-Model)\n",
    "- [How to Use a Trained NLU Classifications Model for Analysis](#5.-How-to-Use-a-Trained-NLU-Classifications-Model-for-Analysis)\n",
    "- [How to Delete a NLU Classifications Model](#6.-How-to-Delete-a-NLU-Classifications-Model)\n",
    "\n",
    "To start, we will need a NLU instance which will provide (among other things) a necessary API key. To provision an instance of NLU visit: [https://cloud.ibm.com/catalog/services/natural-language-understanding](https://cloud.ibm.com/catalog/services/natural-language-understanding). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 1. Add Your NLU Service Credentials Here.\n",
    "\n",
    "See the following for authenticating to Watson services: [https://cloud.ibm.com/docs/watson?topic=watson-iam](https://cloud.ibm.com/docs/watson?topic=watson-iam). It will suffice to use the auto-generated service credentials when you instantiated the NLU service.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Add your NLU credentials here\n",
    "api_key = 'YOUR_API_KEY'\n",
    "url = 'YOUR_URL'\n",
    "\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "auth = IAMAuthenticator(api_key)\n",
    "nlu = NaturalLanguageUnderstandingV1(version='2021-03-25', authenticator=auth)\n",
    "\n",
    "nlu.set_service_url(url)\n",
    "\n",
    "print(\"Successfully connected with the NLU service\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully connected with the NLU service\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to Create Training Data\n",
    "\n",
    "NLU Classifications training data requires a list of text documents, each annotated by one or more labels. \n",
    "\n",
    "The training data for NLU Classifications needs to be in the following JSON format:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"text\": \"document 1\",\n",
    "        \"labels\": [\"label1\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"document 2\",\n",
    "        \"labels\": [\"label2\", \"label3\"]\n",
    "    }\n",
    "]\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Create JSON file from Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"text\": \"How hot is it today?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Is it hot outside?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will it be uncomfortably hot?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will it be sweltering?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"How cold is it today?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will we get snow?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Are we expecting sunny conditions?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Is it overcast?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will it be cloudy?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"How much rain will fall today?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save Training data in a file\n",
    "import json\n",
    "\n",
    "training_data_filename = 'training_data.json'\n",
    "\n",
    "with open(training_data_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_data, f, indent=4)\n",
    "\n",
    "print('Data successfully saved locally in ' + training_data_filename)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data successfully saved locally in training_data.json\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert Data from NLC to NLU Format (Optional to Run)\n",
    "\n",
    "The cell below provides a way of converting the training data stored **locally** in CSV format (required by [Watson Natural Language Classifier](https://cloud.ibm.com/docs/natural-language-classifier?topic=natural-language-classifier-using-your-data#training-structure)) to JSON format required by NLU Classifications training data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Set path to training data file used to train Natural Language Classifier\n",
    "nlc_training_data_file_name = 'nlc_training_data.csv'\n",
    "\n",
    "## Imports\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "\n",
    "def convert_nlc_to_nlu(filename):\n",
    "    \n",
    "    nlu_data = []\n",
    "\n",
    "    with open(nlc_training_data_file_name, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            text = row[0]\n",
    "            labels = row[1:]\n",
    "            # Convert the text and label in NLU training data JSON object\n",
    "            data_dict = {\n",
    "                'text': text,\n",
    "                'labels': labels\n",
    "            }\n",
    "            nlu_data.append(data_dict)\n",
    "\n",
    "    return nlu_data\n",
    "\n",
    "nlu_data = convert_nlc_to_nlu(nlc_training_data_file_name)\n",
    "        \n",
    "# Save Training data in a file\n",
    "training_data_filename = 'training_data.json'\n",
    "\n",
    "with open(training_data_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(nlu_data, f, indent=4)\n",
    "\n",
    "print('Data successfully converted to NLU format and saved locally in ' + training_data_filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch Data From NLC (Optional to Run)\n",
    "\n",
    "If you already have an existing Watson Natural Language Classifier (NLC) model, it is possible to fetch the training data from the NLC model and make it available for NLU Classifications. To start, you will need to provide the credentials of your NLC service instance. Additionally, you will need the url that links to the classifer where training data is being fetched from. Directions on finding the url for the classifier can be found on the NLC API documentation: [https://cloud.ibm.com/apidocs/natural-language-classifier?code=python#getclassifier](https://cloud.ibm.com/apidocs/natural-language-classifier?code=python#getclassifier)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NLC_username = \"YOUR_NLC_USERNAME\"\n",
    "NLC_api_key = \"YOUR_NLC_API_KEY\"\n",
    "NLC_classifier_url = \"YOUR_CLASSIFIER_URL\"\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "from contextlib import closing\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "\n",
    "# Provide the filename to save the data downloaded from existing NLC classifier\n",
    "nlc_training_data_file_name = \"nlc_training_data.csv\"\n",
    "\n",
    "# Fetch data from NLC\n",
    "with open(nlc_training_data_file_name, 'w', encoding='utf-8') as out_file:\n",
    "    uri = \"{}/training_data\".format(NLC_classifier_url)\n",
    "    with closing(requests.get(uri, auth=(NLC_username, NLC_api_key), verify=False, stream=True)) as res:\n",
    "        lines = (line.decode('utf-8') for line in res.iter_lines())\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        for row in csv.reader(lines):\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "# Convert to NLU format    \n",
    "nlu_data = convert_nlc_to_nlu(nlc_training_data_file_name)\n",
    "        \n",
    "# Save Training data in a file\n",
    "training_data_filename = 'training_data.json'\n",
    "\n",
    "with open(training_data_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(nlu_data, f, indent=4)\n",
    "    \n",
    "print('Data successfully converted to NLU format and saved locally in ' + training_data_filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. How to Train a NLU Classifications Model\n",
    "\n",
    "To train a NLU Classifications model using the data created above, utilize the `create_classifications_model` method. To view all functionality, you can also look over the NLU API documentation: [https://cloud.ibm.com/apidocs/natural-language-understanding?code=python](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open(training_data_filename, 'rb') as file:\n",
    "    model = nlu.create_classifications_model(language='en', training_data=file, training_data_content_type='application/json', name='MyClassificationsModel', model_version='1.0.1').get_result()\n",
    "    \n",
    "    print(\"Created a NLU Classifications model:\")\n",
    "    print(json.dumps(model, indent=4))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created a NLU Classifications model:\n",
      "{\n",
      "    \"name\": \"MyClassificationsModel\",\n",
      "    \"user_metadata\": null,\n",
      "    \"language\": \"en\",\n",
      "    \"description\": null,\n",
      "    \"model_version\": \"1.0.1\",\n",
      "    \"version\": \"1.0.1\",\n",
      "    \"workspace_id\": null,\n",
      "    \"version_description\": null,\n",
      "    \"status\": \"starting\",\n",
      "    \"notices\": [],\n",
      "    \"model_id\": \"9bb62cb1-b26a-4e3e-adfb-e62f3037e60c\",\n",
      "    \"features\": [\n",
      "        \"classifications\"\n",
      "    ],\n",
      "    \"created\": \"2021-07-27T20:01:06Z\",\n",
      "    \"last_trained\": \"2021-07-27T20:01:06Z\",\n",
      "    \"last_deployed\": null\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. How to Get Status of a NLU Classifications Model\n",
    "\n",
    "We can inspect the NLU Classifications model that has been recently created using the `get_classifications_model` method and passing in the `model_id`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model_id = model['model_id']\n",
    "model_to_view = nlu.get_classifications_model(model_id=model_id).get_result()\n",
    "\n",
    "print(\"Information about the created NLU Classifications model:\")\n",
    "print(json.dumps(model_to_view, indent=4))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Information about the created NLU Classifications model:\n",
      "{\n",
      "    \"name\": \"MyClassificationsModel\",\n",
      "    \"user_metadata\": null,\n",
      "    \"language\": \"en\",\n",
      "    \"description\": null,\n",
      "    \"model_version\": \"1.0.1\",\n",
      "    \"version\": \"1.0.1\",\n",
      "    \"workspace_id\": null,\n",
      "    \"version_description\": null,\n",
      "    \"status\": \"standby\",\n",
      "    \"notices\": [],\n",
      "    \"model_id\": \"9bb62cb1-b26a-4e3e-adfb-e62f3037e60c\",\n",
      "    \"features\": [\n",
      "        \"classifications\"\n",
      "    ],\n",
      "    \"created\": \"2021-07-27T20:01:06Z\",\n",
      "    \"last_trained\": \"2021-07-27T20:01:06Z\",\n",
      "    \"last_deployed\": \"2021-07-27T20:07:31Z\"\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. How to Use a Trained NLU Classifications Model for Analysis\n",
    "\n",
    "Once the NLU Classifications model is fully trained, the `status` located in the cell above will turn to `available` indicating the model can be used for analysis (training above will take a few minutes to complete). Once ready, utilize the `analyze` method by passing in text, HTML, or public webpage urls. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from ibm_watson.natural_language_understanding_v1 import Features, ClassificationsOptions\n",
    "\n",
    "text = \"What is the expected high for today?\"\n",
    "\n",
    "analysis = nlu.analyze(text=text, features=Features(classifications=ClassificationsOptions(model=model_id))).get_result()\n",
    "\n",
    "print(\"Analysis response from trained NLU Classifications model:\")\n",
    "print(json.dumps(analysis, indent=4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analysis response from recently trained model:\n",
      "{\n",
      "    \"usage\": {\n",
      "        \"text_units\": 1,\n",
      "        \"text_characters\": 36,\n",
      "        \"features\": 0\n",
      "    },\n",
      "    \"language\": \"en\",\n",
      "    \"classifications\": [\n",
      "        {\n",
      "            \"confidence\": 0.562519,\n",
      "            \"class_name\": \"temperature\"\n",
      "        },\n",
      "        {\n",
      "            \"confidence\": 0.433996,\n",
      "            \"class_name\": \"conditions\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. How to Delete a NLU Classifications Model\n",
    "\n",
    "Use the `delete_classifications_model` method to remove a specific classification model via a `model_id`. This operation can be verified by listing all the existing models with `list_classifications_models`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "deleted_model = nlu.delete_classifications_model(model_id=model_id)\n",
    "updated_models_list = nlu.list_classifications_models().get_result()\n",
    "\n",
    "print(\"The NLU Classifications model created in this tutorial has been deleted:\")\n",
    "print(json.dumps(updated_models_list, indent=4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The NLU Classifications model created in this tutorial has been deleted:\n",
      "{\n",
      "    \"models\": []\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}